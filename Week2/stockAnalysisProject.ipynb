{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb41268-dff3-4ae7-80e7-5b47be53af38",
   "metadata": {},
   "source": [
    "# Week 1\n",
    "### Large Cap US Stock Analysis\n",
    "NVDA- NVIDIA\n",
    "MS- Morgan Stanley\n",
    "BX-  Blackstone\n",
    "JPM- JP Morgan\n",
    "GE- General Electric Aerospace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67997a8f-c99b-4d3f-a85e-96d3b296cdae",
   "metadata": {},
   "source": [
    "Importing \n",
    "### Note:\n",
    "define tickers here and store their csv file in data folder in the same directory as this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf2da5-9508-4a2a-aba7-413ffb4d01d7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#tickers = [\"NVDA\", \"MS\", \"BX\", \"JPM\", \"GE\"]\n",
    "tickers = [\"AAPL\", \"MSFT\", \"TSLA\", \"AMZN\", \"GOOGL\"]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787c888-47b0-4e03-b252-8d87d7a61908",
   "metadata": {},
   "source": [
    "#### Function to clear up and missing info \n",
    "- uses interpolation to fill most data, then forward fill and backward fill for edge cases at top edge and bottom edge, if data is reliable, we can add argument (limit=1) for ffill and bfill, but if not, then then omitting it helps take care of block of missing value at top and bottom edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6151294-ba0c-4cdc-b2a1-8e84e50872e3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def cleanDF(df):\n",
    "    df.interpolate(method=\"linear\", inplace=True, limit_direction=\"both\")\n",
    "\n",
    "    #for edge cases\n",
    "    df.ffill(inplace=True)\n",
    "    df.bfill(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554546c7-30b7-455c-ae6a-a2616f5c1dbb",
   "metadata": {},
   "source": [
    "#### Function to filter the dataframe to a certain set of period of years from the last available data's date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1e897-e99f-4d50-89f2-2324bf34afde",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def filterYearPeriod(df, years):\n",
    "    #since the data is only recorded to around 2017, taking last data's date as the end of of our period\n",
    "    #Note: the date needs to be in datetime format\n",
    "    lastDate = df['Date'].max()\n",
    "\n",
    "    #defining a cutoff date for time, years can be changed according to will\n",
    "    noOfYears=years\n",
    "    cutoffDate = lastDate -  pd.DateOffset(years = noOfYears)\n",
    "\n",
    "    df = df[df['Date'] >= cutoffDate]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05efd97b-7269-48bd-931b-bcd781a315d7",
   "metadata": {},
   "source": [
    "#### Function to find the technical indicators for df and add them as columns:\n",
    "- Daily Return: % change in closing price\n",
    "- 7-day Moving Average of closing price\n",
    "- 30-day Moving Average of closing price\n",
    "- Rolling Volatility (30d): Standard deviation of returns over the last 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2307b1dc-6f16-4a36-b655-c5faa5762fba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def addTechnicalIndicators(df):\n",
    "    #daily return (%)\n",
    "    df['Daily Return (%)'] = df['Close'].pct_change()*100\n",
    "    #using min_periods=1 to allow row 2 and onwards to have data. row 1 for daily return and std deviation cannot have data as no preceding data to work on for ma it can still just use current closing value\n",
    "    #7 day moving average\n",
    "    df['7-Day Moving Average'] = df['Close'].rolling(window=7, min_periods=1).mean()\n",
    "    #30 day moving average\n",
    "    df['30-Day Moving Average'] = df['Close'].rolling(window=30, min_periods=1).mean()\n",
    "    #rolling volatility over 30 days\n",
    "    df['Rolling Volatility (30d)'] =  df['Close'].rolling(window=30, min_periods=1).std()\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eca4556-9517-4da2-b3b6-cf39ccc4e3d7",
   "metadata": {},
   "source": [
    "##### Importing Data and Loading to MultiIndexed DataFrames\n",
    "- with Ticker and Date as Indices\n",
    "- Converting Date to datetime format\n",
    "- Then cleaning up to fill missed values using interpolation or forward fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e7b3d-50ed-4090-ba14-3a050cfa76a5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataFrames = {}\n",
    "period=10\n",
    "\n",
    "for ticker in tickers:\n",
    "    dataFrame = pd.read_csv(f'data/{ticker.lower()}.us.txt')\n",
    "    #converting date to datetime format\n",
    "    dataFrame['Date'] = pd.to_datetime(dataFrame['Date'])\n",
    "    #sorting on basis of date\n",
    "    dataFrame.sort_values('Date', inplace=True)\n",
    "    #filtering last 10 years data\n",
    "    dataFrame = filterYearPeriod(dataFrame, period)\n",
    "\n",
    "    #filling missing values\n",
    "    dataFrame = cleanDF(dataFrame)\n",
    "    #adding ticker column\n",
    "    dataFrame['Ticker'] = ticker\n",
    "    dataFrame.set_index(['Ticker', 'Date'], inplace=True)\n",
    "    dataFrame = addTechnicalIndicators(dataFrame)\n",
    "    \n",
    "    dataFrames[ticker]= dataFrame\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472924d4-5377-446d-a441-97adba977c90",
   "metadata": {},
   "source": [
    "#### Functions to compute average daily return and mean rolling volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03dc2d7-4985-46a3-ad9b-28e0825f2e6a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def avgReturn(df):\n",
    "    return df['Daily Return (%)'].mean()\n",
    "def meanMonthlyRollingVolatility(df):\n",
    "    #creating a deep copy to not change original file\n",
    "    sudodf = df.copy(deep=True)\n",
    "    #adds another column with datetime only accurate to the month to help get monthly rolling volatility\n",
    "    sudodf['Year-Month'] =  sudodf.index.get_level_values('Date').to_period('M')\n",
    "    #df of monthtly volatility\n",
    "    monthlyVolatility = sudodf.groupby(['Year-Month'])['Rolling Volatility (30d)'].mean()\n",
    "\n",
    "    #now finding most volatile month and volatility in that month\n",
    "    month = monthlyVolatility.idxmax()\n",
    "    volatility = monthlyVolatility.max()\n",
    "\n",
    "    return [monthlyVolatility, month, volatility]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd6e0a-47c0-4173-9f1c-d28c477cac16",
   "metadata": {},
   "source": [
    "- Now we use these functions to get average daily return and volatility and format and print the information for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81377251-fd8e-4f5e-9d55-25a4061d3077",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "avgReturns=[]\n",
    "greatestMonthlyAvgVolatility=[]\n",
    "correspondingMonths=[]\n",
    "for i,dataFrame in enumerate(dataFrames.values()):\n",
    "    avgRet=avgReturn(dataFrame)\n",
    "    print(f\"{tickers[i]} had a average daily return of {avgRet}% over the last 10 years of data.\")\n",
    "    avgReturns.append(avgRet)\n",
    "    \n",
    "    vol = meanMonthlyRollingVolatility(dataFrame)\n",
    "    print(f\"{tickers[i]} had the most volatile month - {vol[1]} with a average volatility of {vol[2]}\")\n",
    "    greatestMonthlyAvgVolatility.append(vol[2])\n",
    "    correspondingMonths.append(vol[1])\n",
    "    print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "greatestAvgReturn=max(avgReturns)\n",
    "for i,ele in enumerate(avgReturns):\n",
    "    if avgReturns[i]==greatestAvgReturn:\n",
    "        print(f\"The stock {tickers[i]} had the greatest average daily return of {greatestAvgReturn}\")\n",
    "        print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "maximumVolatility = max(greatestMonthlyAvgVolatility)\n",
    "maximumVolatilityStock = []\n",
    "for i,ele in enumerate(greatestMonthlyAvgVolatility):\n",
    "    if ele == maximumVolatility:\n",
    "        maximumVolatilityStock.append([tickers[i], correspondingMonths[i]])\n",
    "for stock in maximumVolatilityStock:\n",
    "    print(f\"The stock {stock[0]} had the most volatile month - {stock[1]} with a volatility of {maximumVolatility}.\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe5533e-36a9-4454-8fb5-9c7d5f79ff80",
   "metadata": {},
   "source": [
    "#### Visualization Function\n",
    "- To visualize the data we use matplotlib\n",
    "- Creating function to specify parameter and tickers to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d9c972-786f-4fd8-a5b1-fd00895f4c60",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def createPlot(tickers, parameter):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            df = dataFrames[ticker]\n",
    "            dates = df.index.get_level_values('Date')\n",
    "            try:\n",
    "                parameterValues = df[parameter]\n",
    "                plt.plot(dates, parameterValues, label=ticker)\n",
    "            except:\n",
    "                print(f\"Invalid parameter- {parameter}\")\n",
    "\n",
    "        except KeyError:\n",
    "            print(f\"Ticker- {ticker} does not exist\")\n",
    "    #to check if atleast one valid plot has been added\n",
    "    if plt.gca().lines !=0:\n",
    "        plt.title(f'{parameter} of Selected Stocks Over Last {period} Years of Available Data')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(parameter)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ee11cc-c0f2-494b-8ba1-508aaf82afb0",
   "metadata": {},
   "source": [
    "- Using above function to make plots for closing price, daily return and other techincal indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da95ff-65a1-4de0-a763-56636a016e09",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "createPlot(tickers, \"Close\")\n",
    "\n",
    "createPlot(tickers, \"Daily Return (%)\")\n",
    "#daily return of some are hidden by others, so also plot individually\n",
    "for ticker in tickers:\n",
    "    createPlot([ticker], \"Daily Return (%)\")\n",
    "\n",
    "createPlot(tickers, \"7-Day Moving Average\")\n",
    "\n",
    "createPlot(tickers, \"30-Day Moving Average\")\n",
    "\n",
    "createPlot(tickers, \"Rolling Volatility (30d)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96860798-aa44-4755-af57-e3f9ec94f50c",
   "metadata": {},
   "source": [
    "# Week 2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef7769-0ad0-428a-ad6e-8d08018f05e5",
   "metadata": {},
   "source": [
    "## Model Implementation and Evaluation\n",
    "#### Choosing a stock - AMZN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac0d42-16a2-43ba-b18e-746ebf4aa8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "stockTicker = \"AMZN\"\n",
    "stockDF = dataFrames[stockTicker].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d39d0-559a-4311-bfad-493fcd0476c9",
   "metadata": {},
   "source": [
    "#### Splitting dataframe into training-80% and testing-20% datasets on the basis of date\n",
    "- Only creating the index for the split as we still need to create features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e2db56-6651-4027-a917-c8fa72adfc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfRows = stockDF.shape[0]\n",
    "testDataStartIndex = (4*numberOfRows//5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f373ef2f-327e-4bb6-8413-102336620d83",
   "metadata": {},
   "source": [
    "### Linear Regression Model\n",
    "#### Creating past 5 day close value features for each row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589f66fd-b0af-4189-aeea-dc9f27196e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pastCloseFeature(noOfLaggingDays, df):\n",
    "    for i in range(1,1+days):\n",
    "        df[f\"Lag{i}\"] = df[\"Close\"].shift(i)\n",
    "    return df\n",
    "days= 5\n",
    "stockDF = pastCloseFeature(days, stockDF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffd786d-132b-4a03-996c-b4496644d0c8",
   "metadata": {},
   "source": [
    "- Removing rows with NA values\n",
    "- Setting features and target as X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703af6ef-2bd3-4cef-bdbb-c9b8b98c6114",
   "metadata": {},
   "outputs": [],
   "source": [
    "stockDF.dropna(inplace = True)\n",
    "#realigning the index for training and test data split\n",
    "testDataStartIndex -= days\n",
    "X = stockDF[[f\"Lag{i}\" for i in range(1,1+days)]]\n",
    "y = stockDF[\"Close\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e93f1f-7564-4e52-a88e-6f3a56effeb2",
   "metadata": {},
   "source": [
    "#### Separating training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a1a00f-ef5f-4e89-a926-14a2d201c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X, y):\n",
    "    XTrain = X.iloc[:testDataStartIndex]\n",
    "    yTrain = y.iloc[:testDataStartIndex]\n",
    "    XTest = X.iloc[testDataStartIndex:]\n",
    "    yTest = y.iloc[testDataStartIndex:]\n",
    "    return (XTrain, yTrain, XTest, yTest)\n",
    "(XTrain, yTrain, XTest, yTest)= splitData(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679e5d4d-cd1d-45bf-855d-62a44c8bc6d4",
   "metadata": {},
   "source": [
    "#### Model Implementation : Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3ed9ad-aca4-49d4-81f0-1e9d870930f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics  import mean_absolute_error\n",
    "\n",
    "linearRegressionModel = LinearRegression()\n",
    "linearRegressionModel.fit(XTrain, yTrain)\n",
    "yPred = linearRegressionModel.predict(XTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b2f6c1-880f-4762-b774-c86728175a76",
   "metadata": {},
   "source": [
    "##### Visualising the prediction wrt to the true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e56a66d-9b36-4e1c-a14c-b34f1ea32914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPredictionsPlot(predictions, true, parameter, title):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(true.index.get_level_values('Date'), true.values, label=f'Actual {parameter}', color='black')\n",
    "    plt.plot(true.index.get_level_values('Date'), predictions, label=f'Predicted {parameter}', color='blue', alpha=0.7)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(parameter)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "createPredictionsPlot(yPred, yTest, \"Close\", \"Linear Regression: Predictions v/s True Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31780b3-a3b4-41df-9021-02bba4ec0dc5",
   "metadata": {},
   "source": [
    "#### MAE and Directional Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0702ab-9545-4ea3-8096-0676c5f79de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(predictions, true, title):\n",
    "    mae = mean_absolute_error(true, predictions)\n",
    "    print(f\"MAE: {title} - {mae}\")\n",
    "    return mae\n",
    "def directionAccuracy(predictions, true, title):\n",
    "    correctDirection = np.sign(true.values[1:] - true.values[:-1]) == np.sign(predictions[1:] - true.values[:-1])\n",
    "    directionalAccuracy = correctDirection.sum() / len(correctDirection) * 100\n",
    "    print(f\"Directional Accuracy: {title} - {directionalAccuracy}%\")\n",
    "    return directionalAccuracy\n",
    "mae(yPred, yTest, \"Linear Regression\")\n",
    "directionAccuracy(yPred, yTest, \"Linear Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f991bc3-87a6-426f-bb92-c10729f52307",
   "metadata": {},
   "source": [
    "### ARIMA Model\n",
    "- Using statsmodel and converting stockDF to a series with date as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30982e3-6ad7-4367-8935-dbdd0089f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "def getDateSeries(df, parameter, stockTicker):\n",
    "    return df.loc[stockTicker,parameter]\n",
    "stockSeries = getDateSeries(stockDF, 'Close', stockTicker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f8d75-02ef-4b8c-9038-e60e6172c4ff",
   "metadata": {},
   "source": [
    "- Splitting data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe7d06-5833-4c3b-a123-f166fe516c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#realigning test data start index ## only use if linear regression used before this\n",
    "testDataStartIndex+=days\n",
    "trainSeries = stockSeries[:testDataStartIndex]\n",
    "\n",
    "#setting freq of date as business days\n",
    "trainSeries= trainSeries.asfreq('B')\n",
    "testSeries = stockSeries[testDataStartIndex:]\n",
    "\n",
    "testSeries = testSeries.asfreq('B')\n",
    "\n",
    "trainSeries = trainSeries.dropna()\n",
    "testSeries= testSeries.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66c7f30-a560-432d-aaec-7ce90cabe3eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### Method 1\n",
    "- Using only training data to get multistep forecasting recursively\n",
    "###### Method 2\n",
    "- Using real data uptil the last day to get one-step ahead forecasting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e422d0-6eab-45e0-b2af-dd3720bbffc8",
   "metadata": {},
   "source": [
    "#### Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d07d39-ed0a-4446-974a-8499bc5d3cc9",
   "metadata": {},
   "source": [
    "#### Creating model and fitting the data\n",
    "##### (p, d, q) \n",
    "- p is number of lagging components in the representation of prediction as function of past values\n",
    "- d is number of differencing to make the mean constant\n",
    "- q is the number of lagged components of error\n",
    "##### Using autoArima to automatically get best values for p,d,q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc67a934-993b-40e5-a34d-076430392774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from pmdarima import auto_arima\n",
    "def getOptimumOrder(trainSeries):\n",
    "    autoModel=auto_arima(trainSeries, seasonal=False, trace=True, suppress_warnings=True)\n",
    "    optimumOrder=autoModel.order\n",
    "    return optimumOrder\n",
    "#optimumOrder= getOptimumOrder(trainSeries)\n",
    "#to reduce runtime, we only use autoarima once and have optimum order as 5,2,0\n",
    "optimumOrder = (5,2,0)\n",
    "def fitARIMAModel(optimumOrder):\n",
    "    \n",
    "    arimaModel = ARIMA(trainSeries,  order=optimumOrder) \n",
    "    fittedModel = arimaModel.fit()\n",
    "    return fittedModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55807a-3912-4a61-b0d7-9fabbc1d2b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createARIMAForecast(model, title):\n",
    "    lenTest = len(testSeries)\n",
    "    forecast = model.forecast(steps=lenTest)\n",
    "\n",
    "    #Plotting\n",
    "    createPredictionsPlot(forecast, testSeries, \"Close\", f\"ARIMA: Predictions v/s True Values - {title}\")\n",
    "    return forecast\n",
    "pdqs = [[(5,2,0),\"Optimum acc to AutoArima 5.2.0\"],[(5,1,0), \"Generally used for Financial Data 5.1.0\"], [(5,2,5),\"Manually arrived at 5.2.5\"]]\n",
    "for pdq,title in pdqs:\n",
    "    model = fitARIMAModel(pdq)\n",
    "    forecast = createARIMAForecast(model, title)\n",
    "    mae(forecast, testSeries, f\"ARIMA: {title}\")\n",
    "    directionAccuracy(forecast, testSeries, f\"ARIMA: {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daef464-b4ce-474c-84ad-0131e0da395e",
   "metadata": {},
   "source": [
    "#### Method 2\n",
    "- Since statsmodels ARIMA model does not allow updating the model, we have to retrain it to allow it use new data every day on a rolling basis\n",
    "#### Note: Extremely Time Taking-  only uncomment last function call if want to run it \n",
    "- Set percent to the first nth part to predict, so if 1/10th of it is to be predicted set percent to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afaf7c8-ea90-4da4-a4e1-2bb09291d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullSeries =  pd.concat([trainSeries, testSeries])\n",
    "percent = 10\n",
    "def rollingARIMAModel(order):\n",
    "    \n",
    "    history = list(trainSeries)\n",
    "    rollingPredictions=[]\n",
    "    for t in range(len(testSeries)//percent):\n",
    "        model = ARIMA(history, order=order)\n",
    "        fittedModel = model.fit()\n",
    "        prediction = fittedModel.forecast()[0]\n",
    "    \n",
    "        rollingPredictions.append(prediction)\n",
    "        history.append(testSeries.iloc[t])\n",
    "    return rollingPredictions\n",
    "def callRollingModels(orders):\n",
    "    for pdq,title in orders:\n",
    "        modelPredictions = rollingARIMAModel(pdq)\n",
    "        createPredictionsPlot(modelPredictions, testSeries.iloc[:len(testSeries)//percent] ,'Close',title)\n",
    "        mae(modelPredictions, testSeries.iloc[:len(testSeries)//percent], f\"ARIMA: {title}\")\n",
    "        directionAccuracy(modelPredictions, testSeries.iloc[:len(testSeries)//percent], f\"ARIMA: {title}\")\n",
    "#callRollingModels([pdqs[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e59cb-6f56-4e7b-9618-372fb188c021",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "##### RSI Calculation\n",
    "- 14 day based RSI, using SMA, can also be done with EMA for smoothness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cceb97-5229-4978-9edc-4ab0c4048723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRSI(series, window=14):\n",
    "    #difference between t row  and t-1 row value\n",
    "    delta = series.diff()\n",
    "\n",
    "    gains = delta.clip(lower=0)\n",
    "    losses = -delta.clip(upper=0) #absoulte value of losses\n",
    "\n",
    "    avgGain = gains.rolling(window=window).mean()\n",
    "    avgLoss = losses.rolling(window=window).mean()\n",
    "\n",
    "    rs = avgGain/avgLoss\n",
    "    rsi = 100 - (100/(1+rs))\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5812cec6-89be-41fe-a854-170320cfd6d6",
   "metadata": {},
   "source": [
    "- Taking new copy of stock dataframe to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b37969-a7f2-4ef2-b4d0-9d93b82da3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfdf = stockDF.copy(deep=True)\n",
    "rfdf[\"RSI\"] = computeRSI(rfdf['Close'], 14)\n",
    "\n",
    "#also adding next day's close as what we want to predict\n",
    "rfdf['Target'] = rfdf['Close'].shift(-1)\n",
    "\n",
    "#top 13 would have NaN values so we drop them\n",
    "rfdf = rfdf.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce361c83-90c2-4500-8beb-0d2315999737",
   "metadata": {},
   "source": [
    "##### Splitting the data into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9872548c-e542-40a5-bedd-f3a487a29b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xrf= rfdf.drop(columns=['Target', 'Close']) # feature set\n",
    "yrf = rfdf['Target']\n",
    "(XTrain, yTrain, XTest, yTest) = splitData(Xrf, yrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf0bcf-5f45-4c6b-8c31-b0c2dfb8c5ee",
   "metadata": {},
   "source": [
    "#### Building Random Forest Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d8097c-4f52-473a-ab9e-9b56d163d8c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#random_state is for reproducibility, i use 799 from my entry number\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=799)\n",
    "rf.fit(XTrain, yTrain)\n",
    "\n",
    "yPred = rf.predict(XTest)\n",
    "\n",
    "createPredictionsPlot(yPred, yTest, 'Close', \"Random Forest: Predictions v/s True Values\")\n",
    "\n",
    "mae(yPred, yTest, \"Random Forest\")\n",
    "directionAccuracy(yPred, yTest, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71a9e5-82a2-4cf5-b933-12d4c62ee4ae",
   "metadata": {},
   "source": [
    "- Due to reaching new high in stock price, the random forest errs and defaults to a constant value, as it is incapable of extrapolating data\n",
    "- We can try to change this by making the features and target relative and not absolute on basis of price\n",
    "      - We will use returns instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c8a90-213d-4d47-9d06-50e9ddc57037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfdf = stockDF.copy(deep=True)\n",
    "rfdf[\"RSI\"] = computeRSI(rfdf['Close'], 14)\n",
    "\n",
    "#new target - return -next day's return based on today's close\n",
    "rfdf['Return'] = rfdf['Close'].pct_change().shift(-1)\n",
    "\n",
    "\n",
    "rfdf = rfdf.dropna()\n",
    "\n",
    "Xrf= rfdf.drop(columns=['Return', 'Close']) # feature set\n",
    "yrf = rfdf['Return']\n",
    "(XTrain, yTrain, XTest, yTest) = splitData(Xrf, yrf)\n",
    "\n",
    "#to recompute the prices we will store the actual closing prices and then use return pct and compute return price\n",
    "actualClose =rfdf['Close'].iloc[testDataStartIndex:]\n",
    "\n",
    "\n",
    "relativeRF = RandomForestRegressor(n_estimators=100, random_state=799)\n",
    "relativeRF.fit(XTrain, yTrain)\n",
    "\n",
    "relativeyPred = relativeRF.predict(XTest)\n",
    "\n",
    "#back converting to prices\n",
    "yTestPrice = actualClose.values[:-1] * (1 + yTest[:-1])\n",
    "predictedPrice = actualClose.values[:-1] * (1 + relativeyPred[:-1])\n",
    "\n",
    "\n",
    "createPredictionsPlot(predictedPrice, yTestPrice, 'Close', \"Relative Random Forest: Predictions v/s True Values\")\n",
    "\n",
    "mae(predictedPrice, yTestPrice, \"Relative Random Forest\")\n",
    "directionAccuracy(predictedPrice, yTestPrice, \"Relative Random Forest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51baabae-66de-44f9-a312-7391dd6f4293",
   "metadata": {},
   "source": [
    "- This results in much better MAE and slightly better Directional Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d764dd-b4c1-4f4c-9b90-00369b87604f",
   "metadata": {},
   "source": [
    "### Best Model - Linear Regression - Decent MAE and Best Directional Accuracy\n",
    "#### To backtest we first make a buy or sell signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462066b-d768-42c2-a24d-c7796b7eae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "days= 5\n",
    "stockDF = pastCloseFeature(days, stockDF)\n",
    "stockDF.dropna(inplace = True)\n",
    "#realigning the index for training and test data split\n",
    "testDataStartIndex -= days\n",
    "X = stockDF[[f\"Lag{i}\" for i in range(1,1+days)]]\n",
    "y = stockDF[\"Close\"]\n",
    "(XTrain, yTrain, XTest, yTest)= splitData(X,y)\n",
    "currentPrice = yTest.shift(1).values\n",
    "yPred = linearRegressionModel.predict(XTest)\n",
    "signals = np.where(yPred > currentPrice , 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736bb98-3088-491b-b470-7021462d6071",
   "metadata": {},
   "source": [
    "#### Simulating trading based on signals\n",
    "- We buy when the signal is 1\n",
    "- and we hold when the signal is 0 -  no return\n",
    "- we sell at the end of the day- simplest backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ecdc9-86a0-470f-92dc-aa1b946f1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual return = (next day's price - today's price) / today's price\n",
    "actualReturns = (yTest.values - currentPrice) / currentPrice\n",
    "actualReturns = np.nan_to_num(actualReturns, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "# strategy return = actual return * signal (i.e., 0 if not invested)\n",
    "strategyReturns = actualReturns * signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862c5109-921e-4d61-a189-9d3cee016bde",
   "metadata": {},
   "source": [
    "#### Now we simulate the portfolio\n",
    "##### Assuming a intial capital of 1000 USD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb649ea-b817-4981-9e40-0501dd08d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iniCap = 1000\n",
    "portfolio = [iniCap]\n",
    "\n",
    "for ret in strategyReturns:\n",
    "    newValue = portfolio[-1] * (1 + ret)\n",
    "    portfolio.append(newValue)\n",
    "\n",
    "# removing the first element to match lengths\n",
    "portfolio = portfolio[1:]\n",
    "print(portfolio[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbda953-020b-40aa-8264-e907aac7fea6",
   "metadata": {},
   "source": [
    "- To visualize the portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d77a3d-da46-41a4-b3f5-314723c36cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(yTest.index.get_level_values('Date'), portfolio)\n",
    "plt.title(\"Backtest\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Portfolio Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0815b-248a-40e5-98c1-ec7d941a2b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c6e81-6436-48dc-be1d-0d9385d49508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00f4ba-d5b9-4eda-818d-a7c37cef75ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
